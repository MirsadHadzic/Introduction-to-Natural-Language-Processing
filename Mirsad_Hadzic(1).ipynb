{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "453bb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03e6a2",
   "metadata": {},
   "source": [
    "(20pts) Data Preprocessing:\n",
    "Perform data cleaning tasks such as removing HTML tags, special characters, and irrelevant symbols from the movie reviews.\n",
    "Tokenize the text into individual words or subword units to prepare them for further analysis.\n",
    "Convert the text to lowercase to ensure consistency.\n",
    "Remove stop words from the text that do not carry much sentiment or meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6fa1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\anes\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\anes\\anaconda3\\lib\\site-packages (from BeautifulSoup4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afb36fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "#words = movie_reviews\n",
    "#letters_only = re.sub(['^a-zA-Z'], \" \", movie_reviews.get_text())\n",
    "#print(letters_only)\n",
    "\n",
    "#stopwords = [w for w in words if w not in stopwords.words['english']]\n",
    "#print(stopwords)\n",
    "#w = sorted(set(movie_reviews.words()))\n",
    "#print(w)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "for category in movie_reviews.categories()\n",
    "for fileid in movie_reviews.fileids(category)]\n",
    "all_words = nltk.FreqDist(w.lower for w in movie_reviews.words())\n",
    "word_features = list(all_words.keys())[:2000]\n",
    "#print(all_words)\n",
    "stops = set(stopwords.words('english'))\n",
    "wo_stopwords = nltk.FreqDist(w for w in all_words if w not in stops)\n",
    "word_features2 = list(wo_stopwords.keys())[:2000]\n",
    "def preprocessing(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    letters_only = re.sub(['^a-zA-Z'], \" \", review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    wo_stopwords = [w for w in words if w not in stops]\n",
    "    tokens = nltk.word_tokenize(wo_stopwords)\n",
    "    return (\" \".join( wo_stowpords ))\n",
    "#preprocessing(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f309be",
   "metadata": {},
   "source": [
    "(20pts) Exploratory Data Analysis (EDA):\n",
    "Perform an exploratory analysis on the dataset to gain insights into the distribution of positive and negative movie reviews.\n",
    "Visualize the data using appropriate graphs or charts to understand the sentiment distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5575daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CategorizedCorpusReader.words of <CategorizedPlaintextCorpusReader in 'C:\\\\nltk_data\\\\corpora\\\\movie_reviews'>>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cb33632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to C:\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c493806",
   "metadata": {},
   "source": [
    "(15pts) Feature Extraction:\n",
    "a. Extract features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33fb9573",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preprocessing(movie_reviews\u001b[38;5;241m.\u001b[39mcategories()\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_list'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a18af6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c27cb7e",
   "metadata": {},
   "source": [
    "(45pts) Model Selection and Training:\n",
    "Split the dataset into training and testing sets.\n",
    "Train the selected model on the training set.\n",
    "Evaluate the model's performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b75cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(w.lower for w in movie_reviews.words())\n",
    "word_features = list(all_words.keys())[:2000]\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features \n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
